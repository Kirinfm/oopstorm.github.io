---
layout: pages
title: 数学之美
date: 2018.12.30
tags: bookworms
---

## 数学之美 | [8.9](https://book.douban.com/subject/26163454/)

* 语言和数学的产生都是为了同一个目的 —— 记录和传播信息

### 文字和语言 vs 数字和信息

* 随着文明的进步，信息量的增加，埃及的象形文字数量便不再随着文明的发展而增加了，因为没有人能够学会和记住这么多的文字。于是，概念的第一次概括和归类就开始了。在古埃及的象形文字中，读音相同的词可能用同一个符号记录。

* 文字按照意思来聚类，最终会带来一些歧义性。而解决这个问题的方法，都是依靠上下文。但也有个别做不到的时候，对上下文建立的概率模型再好，也有失灵的时候。

* 翻译这件事之所以能达成，仅仅是因为不同的文字系统在记录信息上的能力是等价的。进一步讲，文字只是信息的载体，而非信息本身。那么不同文字，而用其他的载体（比如数字）是否可以存储同样意义的信息呢？这个答案是肯定的，这也是我们今天现代通信的基础。

* 信息的冗余是信息安全的保障。只要有一份内容完好保留下来，原有的信息就不会丢失，这对信道编码有指导意义

* 文字是出现在远古“信息爆炸”导致人们的头脑装不下这些信息的时候，那么数字的出现则是在人们的财产多到需要数一数才搞清楚有多少的时候

* 几乎所有的文明都采用了十进制。那么是否有文明采用二十进制呢，也就是说他们数完全部的手指和脚趾才开始进位呢？答案是肯定的，这就是玛雅文明。因此，玛雅人的一个世纪，他们称为太阳纪，是四百年。2012年正好是目前这个太阳纪的最后一年，2013年将是新的太阳纪的开始。不知从何时起，2012年这个太阳纪的最后一年被讹传为世界的最后一年

* 罗马人用 I 代表个，V 代表 5，X 代表 10，L 代表 50，C 代表 100，D 代表 500，M 代表 1000，再往上就没有了

* 在中国，解码的规则是乘法。200 万的写法含义是 `2*100*10 000`；而在罗马，解码规则是加减法 —— 小数字出现在大数字左边为减，右边为加。比如 IV 表示 5-1=4，VII 表示 5+2=7

* 描述数字最有效的是古印度人，他们发明了包括 0 在内的 10 个阿拉伯数字。它们由阿拉伯人传入欧洲后，马上得到普及。只是欧洲人并不知道这些数字的真正发明者是印度人，而把功劳给了“二道贩子”阿拉伯人

* 在罗马体系的文字中，总体来讲，常用字短，生僻字长。而在意型文字中，也是类似，大多常用字笔画少，而生僻字笔画多。这完全符合信息论中的最短编码原理，带来的好处是书写起来省时间、省材料

* 在蔡伦发明纸张以前，书写文字不是一件容易的事情。以中文为例，由于刻一个字的时间相当长，因此要惜墨如金。这就使得我们的古文（书面文字）非常简洁，但是非常难懂，而同时期的口语却和今天的白话差别不大

* 在通信时，如果信道较宽，信息不必压缩就可以直接传递；而如果信道很窄，信息在传递前需要尽可能地压缩，然后在接收端进行解压缩

* 《圣经》的写作持续了很多世纪，后世的人在做补充时，看到的是几百年前甚至上千年前原作的抄本。抄写的错误便在所难免。古犹太人抄写圣经，要检查每一行、每一列的校验是否正确

### 自然语言处理 —— 从规则到统计

* 基于统计的自然语言处理方法，在数学模型上和通信是相通的，甚至就是相同的。因此，在数学意义上自然语言处理又和语言的初衷 —— 通信联系在一起了。但是，科学家们认识到这个联系却花了几十年的时间

### 谈谈中文分词

* 在不少人看来，分词技术只是针对亚洲语言的，而罗马体系的拼音语言没有这个问题，其实不然。也许大家想不到，中文分词的方法也被应用到英语处理，主要是手写体识别中。因为在识别手写体时，单词之间的空格就不很清楚了。中文分词方法可以帮助判别英语单词的边界

* 中文分词现在是一个已经解决了的问题，提高的空间微乎其微了。只要采用统计语言模型，效果都差不到哪里去

* 虽然可以对不同的应用构造不同的分词器，但是这样做不仅非常浪费，而且也不必要。更好的方法是让一个分词器同时支持不同层次的词的切分。也就是说，上面的"清华大学"既可以被看成一个整体，也可以被切分开，然后由不同的应用自行决定采用哪个颗粒度的切分

### 信息的度量和作用

* 一条信息的信息量和它的不确定性有着直接的关系。可以认为，信息量就等于不确定性的多少

* 信息熵（Entropy）一般用符号 H 表示，单位是比特。变量的不确定性越大，熵也就越大，把它搞清楚所需要的信息量也就越大

* 合理利用信息，而不是玩弄什么公式和机器学习算法，是做好搜索的关键

* 信息的作用在于消除不确定性，自然语言处理的大量问题就是找相关的信息

* 当获取的信息和要研究的事物有关系时，这些信息才能帮助我们消除不确定性。香农在信息论中提出了一个"互信息"的概念作为对两个随机事件"相关性"的量化度量

* 机器翻译中，最难的两个问题之一是词义的二义性（又称歧义性）问题。可以使用互信息来解决这个问题

* 信息论中另外一个重要的概念是"相对熵"，也被称为"交叉熵"。相对熵也用来衡量相关性。
1. 对于两个完全相同的函数，它们的相对熵等于零
2. 相对熵越大，两个函数差异越大；反之，相对熵越小，两个函数差异越小
3. 对于概率分布或者概率密度函数，如果取值均大于零，相对熵可以度量两个随机分布的差异性

### 贾里尼克和现代语言处理

* 小学生和中学生其实没有必要花那么多时间读书，而他们的社会经验、生活能力以及在那时树立起的志向将帮助他们的一生

* 中学阶段花很多时间多读的课程，在大学以后用非常短的时间就可以读完，因为在大学阶段，人的理解力要强得多。因此，一个学生在中小学阶段建立的那一点点优势在大学很快就会丧失殆尽

* 学习（和教育）是一个人一辈子的过程

* 书本的内容可以早学也可以晚学，但是错过了成长阶段却是无法补回来的

### 布尔代数和搜索引擎的索引

* 搜索引擎的原理其实非常简单，建立一个搜索引擎大致需要做这样几件事：自动下载尽可能多的网页；建立快速有效的索引；根据相关性对网页进行公平准确的排序

* 布尔代数基本运算只有“与”（AND）、“或”（OR）和“非”（NOT）三种（后来发现，这三种运算都可以转换成“与非” AND-NOT 一种运算）

### 地图和本地搜索的最基本技术 —— 有限状态机和动态规划

* 地址的文法是上下文有关文法中相对简单的一种，有许多识别和分析的方法，但最有效的是有限状态机

* 如果一条地址能从状态机的开始状态经过状态机的若干中间状态，走到终止状态，那么这条地址就有效，否则无效

* 全球导航的关键算法是计算机科学图论中的动态规划的算法

* 许多失败并不是因为人不优秀，而是做事情的方法不对，一开始追求大而全的解决方案，之后长时间不能完成，最后不了了之

### 余弦定理和新闻的分类

* 不同的新闻，因为文本长度的不同，它们的特征向量各个维度的数值也不同，因此单纯比较各个维度的大小并没有太大意义。但是，向量的方向却有很大的意义。如果两个向量的方向一致，说明相应的新闻用词的比例基本一致。因此，可以通过计算两个向量的夹角来判断对应的新闻主题的接近程度。而要计算两个向量的夹角，就要用到余弦定理了

### 矩阵运算和文本处理中的两个分类问题

* 奇异值分解的优点是能较快地得到结果，因为它不需要一次次地迭代。但是用这种方法得到的分类结果略显粗糙，因此，它适合处理超大规模文本的粗分类。在实际工作中，可以先进行奇异值分解，得到粗分类结果，再利用计算向量余弦的方法，在粗分类结果的基础上，进行几次迭代，得到比较精确的结果

### 不要把鸡蛋放到一个篮子里 —— 谈谈最大熵模型

* 不要把所有的鸡蛋放在一个篮子里，其实就是最大熵原理的一个朴素的说法，因为当我们遇到不确定性时，就要保留各种可能性

### 拼音输入法的数学原理

* 使用各种复杂编码输入法的人在脱稿打字时，速度只有他在看稿打字时的一半到四分之一

### 布隆过滤器

* 布隆过滤器的好处在于快速、省空间，但是有一定的误识别率。常见的补救办法是再建立一个小的白名单，存储那些可能被误判的邮件地址

### 维特比和他的维特比算法

* 利用动态规划，可以解决任何一个图中的最短路径问题。而维特比算法是针对一个特殊的图 —— 篱笆网络的有向图（Lattice）的最短路径问题而提出的。它之所以重要，是因为凡是使用隐含马尔可夫模型描述的问题，都可以用它来解码，包括今天的数字通信、语音识别、机器翻译、拼音转汉字、分词等
